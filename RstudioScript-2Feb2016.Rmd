RNA-Seq Read Processing and Alignment with TopHat2
===============================================================

Installing the required packages for R:
This is to be done in the R command line and not in R studio
source("http://www.Bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")

Getting started in R:
Set the working directory > setwd("~/")
Check version installed
```{r}
library(knitr)
```

This will help us when finding our files to source functions:
```{r}
install.packages("rprojroot")
library(rprojroot)
# We specify ours is an RStudio project
# The root object contains a function that will help us locate our package r files
# regarless of our current working directory
root <- rprojroot::is_rstudio_project
scriptsPath <- root$make_fix_file(".")("R")
scripts <- dir(root$find_file("R", path = root$find_file()))
scriptsl <- paste(scriptsPath, scripts, sep = "//")
lapply(scriptsl, source)
```

Setting up the system environment to run qsub jobs from within RStudio
```{r}
Sys.setenv(SGE_ROOT="/opt/gridengine")
Sys.setenv(SGE_CELL="default")
Sys.setenv(SGE_ARCH="linux-x64")
Sys.setenv(SGE_EXECD_PORT="537")
Sys.setenv(SGE_QMASTER_PORT="536")
```

Many of the commands and approach are from:
Simon Anders et al., 2013. Count-based differential expression analysis of 
RNA sequencing data using R and Bioconductor. Nature protocols | VOL.8 NO.9 | 2013

Chunk: Analysis and Sequence Data Directory Setting
User:
Define the the folder in the shared folder that will hold the analyses of the time-course/dataset 
you will be working with. In our case, we have two different time-course experiments, Oosporogenesis 
and Oospore Conversion. Below we set which one the script will run analyses for. We also get the 
user to specify what the name of the directory that will hold the reads will be.
```{r}
# Define the path to the shared folder where the main working directory will be.
sharedPath <- "/isilon/biodiversity/users/shared/Pythium_ultimum_RNAseq/"

# What is the name of the overall experiment?
analysis   <- "Oospore_Conversion_TimeCourse/"

# Name of the directory you'll be keeping all the analyses for this pipeline:
workDir    <- "HiSeq_Analyses2"

#Name of the directory to keep the fastq files in:
seqDataDir <- "HiSeq_data2"
```

Chunk: Library Adapter Sequence User Input

User needs to specify the adapter sequences attached to the sequencing reads. This will depend on 
how the libraries were prepared. We prepared our libraries using the Mondrian and SciClone with 
library kits, instruments and kits by NuGen. NuGen kits are designed to work with Illumina 
sequencing platforms and generate libraries with the sequence structure:

5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 
   (N) 
   AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <- region to select as forward adapter
   XXXXXX 
   ATCTCGTATGCCGTCTTCTGCTTG 3'
   
3' TTACTATGCCGCTGGTGGCTCTAGATGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA 
   (N) 
   TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG <- region to select as reverse adapter
   XXXXXX 
   TAGAGCATACGGCAGAAGACGAAC 5'

Where each string of ‘X’ is the unique 4-, 6, or 8-base barcode from the L2 adaptor mix of the 
library construction system (where applicable) and (N) is the library insert.

We will need to remove any adapter sequences from our reads. We will be doing this with SeqPrep. 
SeqPrep specifies that the user must first ensure the adapter sequences they choose are correct by 
doing a "grep" on the reads first:

Before running SeqPrep make sure to check that the program's defaults are indeed the adapters you 
are looking for. Try copying the default forward adapter from this file and grep it against your 
reads doing a word count, also try the same with the reverse adapter with grep. You should see some 
hits. You can also try using (and validating with grep) -A GATCGGAAGAGCACACG -B AGATCGGAAGAGCGTCGT  
as parameters. To find a list of Illumina adapter sequences you should write to Illumina tech 
support TechSupport@illumina.com (they do not like people to share the list of sequences outside of 
their institution).

Chose about 20bp of an adapter sequence where:
1. You see the most hits with grep
2. When you run a command like:
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | head 
   you see the adapter sequence show up at the beginning of a few reads. Also the -A and -B 
   arguments should be as they show up in your data,    SeqPrep searches directly for these 
   sequences without doing reverse complementing.
3. Check the forward and reverse and make sure that you have roughly the same number of hits via a 
   command to count hits like: 
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | wc -l
```{r}
# Notice that the adapter sequences we chose when processing the HiSeq reads
# is from the same region we are choosing for our MiSeq reads, only shorter:

fwdAdapGQ    <- "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"  # Genome Quebec
revAdapGQ    <- "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"  # Genome Quebec

fwdAdapMiSeq <- "AGATCGGAAGAGCACAC"   # MiSeq
revAdapMiSeq <- "AGATCGGAAGAGCGTCGT"  # MiSeq

fwdAdap      <- fwdAdapMiSeq
revAdap      <- revAdapMiSeq
```

User to specify the time-points, if any, for the RNA-Seq experiment:
```{r}
timePoints <- c("0", "12" , "24", "48", "72", "120", "240")
```

Chunk: Path Setting
The following paths are to directories where the references, tools and general requirements are 
located, this depends on the directories actually having been put there:
```{r}
toolsDirPath     <- paste(sharedPath, "tools/",      sep="")
referencesPath   <- paste(sharedPath, "References/", sep="")
cazyPath         <- paste(sharedPath, "CAZy/",       sep="")
bowtie2BuildPath <- "/opt/bio/bowtie2/bowtie2-build"
htseqCountPath   <- "/opt/bio/HTSeq/bin/htseq-count"
prinSeqPath      <- "/opt/bio/prinseq-lite/prinseq-lite"
prinSeqGraphPath <- "/opt/bio/prinseq-lite/prinseq-graphs"
samtools1Path    <- "/opt/bio/samtools1/bin/samtools1"
seqPrepPath      <- "/opt/bio/SeqPrep/SeqPrep"
tophat2Path      <- "/opt/bio/tophat/bin/tophat2"
pyuuRefPath      <- paste(referencesPath, "Pyuu_ref_1ribo_mito_no_repeats.fa", sep = "")
pyuugff3Path     <- paste(referencesPath, "Pyuu_ref_1ribo_mito_no_repeats.gff3", sep = "")
pyuuTranscripts  <- paste(referencesPath, "pythium_ultimum_transcripts.fasta", sep = "")
pyuuProteins     <- paste(referencesPath, "pythium_ultimum_proteins.fasta", sep = "")
```

PrinSeq Options Setting:
```{r}
nmax           <- "-ns_max_n 1"
trimLeft       <- "-trim_left 15"
trimRight      <- "-trim_right 10"
trimTailLeft   <- "-trim_tail_left 5"
trimTailRight  <- "-trim_tail_right 5"
trimQualWindow <- "-trim_qual_window 3"
trimQualType   <- "-trim_qual_type mean"
trimQualRight  <- "-trim_qual_right 32" #consider 30 after running with Andre's modified gff.
trimQualLeft   <- "-trim_qual_left 32"
trimQualRule   <- "-trim_qual_rule lt"
lcMethod       <- "-lc_method dust"
lcThreshold    <- "-lc_threshold 7"
#outGood        <- "processed_merged" Define by user
outBad         <- " -out_bad null"
minLen         <- "-min_len 60"
```

The user does not alter the variables below. The following chunk will integrate the user-defined 
variables from the previous chunk into the script.
```{r}
# Create the working directory for the current analyses:
dir.create(paste(sharedPath, analysis, workDir, sep = ""), showWarnings = TRUE, recursive = FALSE)
# Set the path:
sharedPathAn <- paste(sharedPath, analysis, workDir, "/", sep ="")
# Establish the working directory for R:
setwd(sharedPathAn)
# Verify the working Directory:
getwd()
# Create fastq directory in sharedPath folder based on "seqDataDir":
dir.create(paste(sharedPath, analysis, seqDataDir, sep = ""), showWarnings=TRUE, recursive=FALSE)
pathFastq <- paste(sharedPath, analysis, seqDataDir, "/", sep = "")
```

Bowtie:
Creating Bowtie reference index from the fasta file: 
```{r}
bowind <- "pyuuRef"

cmd    <- paste(bowtie2BuildPath, " -f ", pyuuRefPath, " ", paste(referencesPath, bowind, sep = ""), 
                sep = "")
#system(cmd)
```

Generation of a metadata file for auditing the processing and analysis of reads throughout the 
script. 

The following will generate a metadata file for the information available from the Genome Quebec csv 
file. If such  file is generated otherwise, ensure the formatting and layouts are compatible (i.e., 
column headers and naming structures), and that the csv file is in the correct folder where the 
analyses for the time-course is being done, and skip this step.

**Pull out HiSeq data**
User:
Specify the path to the raw data for the sequencing reads:
```{r}
hiSeqPathcsv <- paste(sharedPath, "Hi.3651-EG", "/", sep = "")
hiSeqPathraw <- paste(sharedPath, "Hi.3651-restricted_permissions", "/", sep = "")
```

**Pull out HiSeq data**
```{r}
# Genome Quebec csv (gQcsv) files are now in raw data folders
gQcsv1 <- list.files(path = hiSeqPathcsv, pattern = glob2rx("HiSeq_Lane1_*.csv"), full.names=TRUE)
gQcsv2 <- list.files(path = hiSeqPathcsv, pattern = glob2rx("HiSeq_Lane2_*.csv"), full.names=TRUE)

# read that csv file
gQmetadata1         <- read.csv(gQcsv1, stringsAsFactors = FALSE)
gQmetadata2         <- read.csv(gQcsv2, stringsAsFactors = FALSE)

gQmetadata          <- rbind(gQmetadata1, gQmetadata2)
gQmetadata$rawPath  <- hiSeqPathraw

# Create otri like we had done for our first MiSeq dataset:
otri1                <- gQmetadata[,c("LibraryName",
                                      "TimePoint",
                                      "Condition",
                                      "LibraryBC",
                                      "RNA_Replicate",
                                      "RNASeq_Replicate",
                                      "TechnicalRep",
                                      "Region",
                                      "FilenamePrefix", 
                                      "rawPath")]
otri1$Read_Direction <- "R1"
otri2                <- otri1
otri2$Read_Direction <- "R2"
metadata             <- rbind(otri1, otri2)

metadata$FastqFilePath  <- paste(metadata$rawPath, metadata$FilenamePrefix, "_",
                                metadata$Read_Direction, ".fastq.gz", sep = "")
metadata$LibraryName    <- sub("Lib_", "", metadata$LibraryName, ignore.case = FALSE)
metadata$LibraryName    <- paste(metadata$LibraryName, "_", metadata$TechnicalRep, sep = "")
metadata$LibraryName    <- sub("H2O", "Tneg-H2O", metadata$LibraryName, ignore.case = FALSE)
metadata$Platform       <- "Illumina"
metadata$ScientificName <- "Pythium ultimum var ultimum"
metadata$BaseCallsName  <- paste(metadata$FilenamePrefix, "_", 
                                 metadata$Read_Direction, ".fastq", sep = "")

write.table(metadata, file = "HiSeq_OosporeConversionTimeCourse_Metadata.csv", 
            append = FALSE, quote = FALSE, sep = ",", row.names = FALSE)

```

User:
Specify the name of the csv file you would like to use for generation of the metadata file if not 
using the csv file generated by sequencing service or if you want to use the file generated in the 
previous chunk: 
```{r}
metadataFileAlternate <- "HiSeq_OosporeConversionTimeCourse_Metadata.csv"
metadata              <-  read.table(paste(sharedPathAn, metadataFileAlternate, sep = ""),
                                    sep = ",", header = TRUE, comment.char = "", quote = "",
                                    as.is = TRUE) 
```

Copy and gunzip files:
```{r}
prefix <- "A_copy_unzip"
cmd <- with(metadata, paste("cp ", 
                FastqFilePath, " ", 
                #sharedPathAn, seqDataDir, "/", basename(FastqFilePath),"\n",
                pathFastq, basename(FastqFilePath), "\n",
                " gunzip ", 
                pathFastq, basename(metadata$FastqFilePath), sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
Clean-up step:
Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Make a metadata table called metadataRawPairs that has the raw reads rows 
collapsed by R1 and R2
```{r}
library("reshape2")
metadataRawPairs <- dcast(data = metadata, LibraryName + Condition + TimePoint + RNASeq_Replicate 
                          ~ Read_Direction, value.var = "BaseCallsName", FUN = c)

metadataRawPairs$ShortName <- paste(metadataRawPairs$Condition, 
                                    metadataRawPairs$TimePoint, 
                                    metadataRawPairs$RNASeq_Replicate, sep = ".")
```

Run FastqPairedEndValidator for the first time on the raw read pairs:
```{r}
prefix <- "B_Validator"
fastqPEValidatorPath <- paste(toolsDirPath, "FastqPairedEndValidator.pl", sep = "")

cmd <-  with (metadataRawPairs, paste(fastqPEValidatorPath, 
                                      " ", pathFastq, R1, " ", pathFastq, R2, sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To show the output of each pair on the console in Rstudio:
```{r}
for (k in 1:nrow(metadataRawPairs)) {
  cat(c(k, metadataRawPairs$R1[k], metadataRawPairs$R2[k]))
  system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".o*", sep = ""))
  cat("\n")
}
```

To remove the output files (only the .e* files) after you are done:
```{r}
system(paste("rm ", sharedPathAn, prefix, "/", prefix, "*", suffix, ".e*", sep = ""))
```

Looking at our raw data:
Look at the raw fastq graphs prior to adapter removal and merging using PrinSeq graph reports of 
raw, unmerged reads, Step 1: .gd file generation:
```{r}
prefix <- "C_PrinSeq_rawGraphs"
cmd    <- MakePrinSeqGraphFiles(metadataRawPairs, metadataRawPairs$R1, prefix,
                                "rawGraphs", metadataRawPairs$R2)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the path to the raw graphs .gd files to the metadataRawPairs tabel:
```{r}
for(k in 1:nrow(metadataRawPairs)){
  metadataRawPairs$RawGraphFiles <- paste(metadataRawPairs$LibraryName, ".rawGraphs.gd", sep = "") 
}
```

PrinSeq graph reports of raw, unmerged reads. Step 2: html file generation:
```{r}
prefix2 <- "C2_PrinSeq_rawHtmlSub"
cmd <- MakePrinSeqHTML(metadataRawPairs, prefix, metadataRawPairs$RawGraphFiles)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

SeqPrep:
Adapter removal and optional merging:
To test if the choice of adapters is good using the first fastq read 1 sequence. Ignore broken pipe
error.  This happens becuase when the stdin of "cat" is small it may finish writing *before* the
exit of the reader, in our case "grep".
```{r}
for (k in 1:nrow(metadataRawPairs)) {
  cat(c(k, metadataRawPairs$R1[k]))
  system(paste("cat ", pathFastq, metadataRawPairs$R1[k], 
               " | head -n 1000000 | grep '", 
               fwdAdap, "' | wc -l ", sep = ""))
  cat("\n")
}

for (k in 1:nrow(metadataRawPairs)) {
  cat(c(k, metadataRawPairs$R2[k]))
  system(paste("cat ", pathFastq, metadataRawPairs$R2[k], 
               " | head -n 1000000 | grep '", 
               revAdap, "' | wc -l ", sep = ""))
  cat("\n")
}
```

Removal of adapters from fastq reads and unzip files. Do this prior to any other 
processing to make them easier to detect.
The option -s is for merging paired end Illumina reads that are overlapping
into a single longer read.
```{r}
prefix <- "D_SeqPrep"
cmd <- with(metadataRawPairs, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, R1,
                  " -r ", pathFastq, R2,
                  " -1 ", pathFastq, LibraryName, ".adapRem.R1.fastq.gz",
                  " -2 ", pathFastq, LibraryName, ".adapRem.R2.fastq.gz",
                  " -A ", fwdAdap,
                  " -B ", revAdap,
#                   " -s ", pathFastq, paste(LibraryName,
#                                            ".adapRemMerged.fastq.gz",
#                                            sep = ""),
                  " \n ",
                  #"gunzip ", pathFastq, LibraryName,".adapRemMerged.fastq.gz",
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To show the output of each pair on the console in Rstudio
```{r}
for(k in 1:nrow(metadataRawPairs)) {
  cat(c(k, metadataRawPairs$R1[k], metadataRawPairs$R2[k]))
  cat("\n")
  system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
  cat("\n")
}
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Record the name of the adapRem fastq files output from processing with SeqPrep:
```{r}
adapRemFastq <- list.files(path = pathFastq, pattern = "adapRem")
```
*** Note, for HiSeq I didn't remove the single reads because I am still assessing results of merging 
the reads. Delete unnecessary fastq files - this should be adjusted so that it matches the basename 
we originally brought in as it is the original fastq raw reads we no longer need to keep in our data 
directory.
```{r}
# Specify the pattern that will match the raw read files
deleteFastq <- list.files(path = pathFastq, pattern = "^HI.3651.*fastq$")

for(k in 1:length(deleteFastq)) {
  cmd <- paste("rm ", pathFastq, deleteFastq[k], sep = "")
  system(cmd)
}
```

Do we need the following if reads are merged?
Validate fastq R1 and R2 pairs order: 
Make a metadata table called metadataAdapRem that has the raw reads rows 
collapsed.
```{r}
library("reshape2")

for(k in 1:nrow(metadata)){metadata$AdaptRemoved <- paste(metadata$LibraryName, "adapRem", 
                                                          metadata$Read_Direction, "fastq", sep=".")
                           }

metadataAdapRem <- dcast(data = metadata, LibraryName + Condition + TimePoint + RNASeq_Replicate 
                         ~Read_Direction, value.var = "AdaptRemoved", FUN = c)

metadataAdapRem$ShortName <- paste(metadataAdapRem$Condition, 
                                   metadataAdapRem$TimePoint, 
                                   metadataAdapRem$RNASeq_Replicate, sep = ".")
```

```{r}
gunzipFastq <- list.files(path = pathFastq, pattern = ".*fastq.gz$")

for(k in 1:length(gunzipFastq)) {
  cmd <- paste("gunzip ", pathFastq, gunzipFastq[k], sep = "")
  system(cmd)
}
```

**Fixed the name format as LibraryName.adapRemMerged.fastq:
Instead of the above for separate reads, the following is for MiSeq 
reads that are merged:
```{r}
# #Make a Metadata table called MetadataAdapRem with raw reads rows collapsed.
# for(k in 1:nrow(metadata)){
#   metadata$AdapRemMerged <- paste(metadata$LibraryName, ".adapRemMerged", ".fastq", sep = "")
# }
# 
# metadataAdapRM <- dcast(data = metadata, LibraryName + Condition + TimePoint + RNASeq_Replicate 
#                         ~ Read_Direction, value.var = "AdapRemMerged", FUN = c)
# 
# metadataAdapRM$ShortName <- paste(metadataAdapRM$Condition, 
#                                   metadataAdapRM$TimePoint, 
#                                   metadataAdapRM$RNASeq_Replicate, sep = ".")
# 
# # We don't need to keep R1 and R2, remove R2 and rename R1 MergedReads?
# metadataAdapRM$R2 <- NULL
# colnames(metadataAdapRM)[colnames(metadataAdapRM) == "R1"] <- "MergedReads"
```

Test for MiSeq adapters on the merged reads - need to re-evaluate utility at 
this step, and review how merging occurs with SeqPrep:
```{r}
# for (k in 1:nrow(metadataAdapRM)) {
#   cat(c(k, metadataAdapRM$MergedReads[k]))
#   system(paste("cat ",
#                pathFastq, metadataAdapRM$MergedReads[k],
#                " | head -n 10000000 | grep '",
#                fwdAdap, "' | wc -l ", sep = ""))
#   cat("\n")
# }
# 
# for (k in 1:nrow(metadataAdapRM)) {
#   cat(c(k, metadataAdapRM$MergedReads[k]))
#   system(paste("cat ",
#                pathFastq, metadataAdapRM$MergedReads[k],
#                " | head -n 10000000 | grep '",
#                revAdap, "' | wc -l ", sep = ""))
#   cat("\n")
# }
```

Not required for Merged reads:
Second round of FastqPairedEndValidator with adapters removed
```{r}
prefix <- "D_Validator" 
cmd <-  with(metadataAdapRem, paste(fastqPEValidatorPath, " ", 
                                    pathFastq, R1, " ", pathFastq, R2, sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

Not Required for Merged reads:
To show the output of each pair on the console in Rstudio
```{r}
for (k in 1:nrow(metadataAdapRem)) {
  cat(c(k, metadataAdapRem$R1[k], metadataAdapRem$R2[k]))
  system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".o*", sep = ""))
  cat("\n")
}
```

As a follow-up of the chunk above, not required for merged reads:
To remove the output files after you are done
```{r}
system(paste("rm ", sharedPathAn, prefix, "/", prefix, "*", suffix, ".e*", sep = ""))
```

Looking at our data after adapter removal (and if merged) with SeqPrep:
PrinSeq Step 1: .gd file generation:
```{r}
prefix <- "E_PrinSeqGD"
cmd    <- MakePrinSeqGraphFiles(metadataAdapRem, metadataAdapRem$R1, prefix, "adapRem", 
                                metadataAdapRem$R2)
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of graph .gd files to the metadataAdapRM (merged), or metadataAdapRem (unmerged) tabel:
```{r}
# For unmerged reads:
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$AdapRemGD <- paste(metadataAdapRem$LibraryName, ".adapRem.gd", sep = "") 
}
# For Merged Reads:
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMGraph <- paste(metadataAdapRM$LibraryName, ".adapRemMerged.gd", sep = "") 
# }
```

PrinSeq graph reports of adapter-removed merged reads. 
Step 2: html file generation:
```{r}
prefix2 <- "E2_PrinSeqGD"
# For unmerged Reads:
cmd     <- MakePrinSeqHTML(metadataAdapRem, prefix, metadataAdapRem$AdapRemGD)

# For merged reads:
# cmd     <- MakePrinSeqHTML(metadataAdapRM, prefix, metadataAdapRM$AdapRMGraph)

suffix  <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Pre-Processing of Merged Reads using PrinSeq::

For the pre-processing with PrinSeq we have three steps, with three sets of qsubs each:

1. Processing input merged reads with the PrinSeq trim and fitlering options
2. Generating graph files of the processed reads
3. Generating html files using the graph files to visualize the outputs

For each set of qsubs, the .log, .gd, and .html outputs are sent to the first folder that also has 
the first stage qsub and bash files. The processed reads are output to the pathfastq folder.

PrinSeq Processing of merged reads:
First stage of quality pre-processing with PrinSeq:

1-1. Filter adapRemMerged.fastq output from SeqPrep by quality: Note, with merging with SeqPrep 
during adapter removal, the reads are already filtered and are of high quality as only the high 
quality reads can be merged.
```{r}
prefix <- "F_PrinSeq_2processed"

cmd <- PrinSeqProcessPE(metaRef=metadataAdapRem, fastq1=metadataAdapRem$R1, 
                        fastq2=metadataAdapRem$R2, outPutSuffix="2processed",
                        trimQualWindow, trimQualType, trimQualRight, trimQualRule, nmax)

# for merged or single end reads, input fastq must be .gz compressed:
# cmd <- PrinSeqProcessSE(metaRef=metadataAdapRM, fastq1=metadataAdapRM$MergedReads,
#                         outPutSuffix="2processedMerged", trimQualWindow, trimQualType, 
#                         trimQualRight, trimQualRule, nmax)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add name of quality-filtered reads .fastq files to the metadata tabel:

For unmerged forward and reverse reads:
```{r}
# Delete singletons:
singletons <- list.files(path = pathFastq, pattern = ".*_singletons.fastq$")
for(k in 1:length(singletons)) {
  cmd <- paste("rm ", pathFastq, singletons[k], sep = "")
  system(cmd)
}

# Rename files as desired:
read1Fastq <- list.files(path = pathFastq, pattern = ".*_1.fastq$", full.names=TRUE)
read2Fastq <- list.files(path = pathFastq, pattern = ".*_2.fastq$", full.names=TRUE)
sapply(read1Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_1.fastq", replacement = ".R1.fastq", pathFastq))
      })
sapply(read2Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_2.fastq", replacement = ".R2.fastq", pathFastq))
      })
processed2Fastq <- list.files(path = pathFastq, pattern = ".*2processed")

# Add fastq names to metadata table:
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed2.R1.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".2processed.R1.fastq", sep = "")
  metadataAdapRem$processed2.R2.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".2processed.R2.fastq", sep = "")
}
```

For merged reads:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMQualFiltFastq <- paste(metadataAdapRM$LibraryName,
#                                              ".2processedMerged.fastq", sep = "") 
# }
```

Delete the older fastq files with adapters removed, only require newest processed.
```{r}
adapRemFastq

for(k in 1:length(adapRemFastq)) {
  cmd <- paste("rm ", pathFastq, adapRemFastq[k], sep = "")
  system(cmd)
}
rm(adapRemFastq)
```

If output previously was compressed within the script, don't need next chunk. Gzip the fastq reads 
that were INPUT to PrinSeq processing in step 1-1, we won't need them, the next step in 1-2 uses the 
OUTPUT processed reads. 
```{r}

# cmd <- with(metadataAdapRM, paste("gzip ", pathFastq, metadataAdapRM$MergedReads, sep = ""))
# sapply(cmd, function(x) system(x))
```

1-2. Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix2 <- "F2_PrinSeqGD"
# For reads not compressed:
cmd <- MakePrinSeqGraphFiles(metadataAdapRem, metadataAdapRem$processed2.R1.Fastq,
                             prefix, "2processed", metadataAdapRem$processed2.R2.Fastq)

# For merged or single-end reads that are .gz compressed:
# cmd <- MakePrinSeqGraphFiles2(metadataAdapRM, metadataAdapRM$AdapRMQualFiltFastq,
#                               prefix, "2processedMerged")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

For unmerged paired-end reads: Add name of graph files to metadata table:
```{r}
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed2GD <- paste(metadataAdapRem$LibraryName, ".2processed.gd", sep = "") 
}
```
For merged or single-end reads: Add name of graph files to metadata table:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMQualFiltGraph <- paste(metadataAdapRM$LibraryName,
#                                          ".2processedMerged.gd", sep = "") 
# }
```

1-3. PrinSeq graph reports of first-stage html file generation:
```{r}
prefix3 <- "F3_PrinSeqGD"

# For paired-end not merged:
cmd <- MakePrinSeqHTML(metadataAdapRem, prefix, metadataAdapRem$processed2GD)

# For merged or single-end reads:
# cmd <- MakePrinSeqHTML(metadataAdapRM, prefix, metadataAdapRM$AdapRMQualFiltGraph)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

2-1. Second stage of quality pre-processing with PrinSeq:
Trim left and right, and Poly-A/T tail removal, round 1
```{r}
prefix <- "G_PrinSeqTrimLRPolyAT"

cmd <- PrinSeqProcessPE(metaRef=metadataAdapRem, fastq1=metadataAdapRem$processed2.R1.Fastq, 
                        fastq2=metadataAdapRem$processed2.R2.Fastq, outPutSuffix="3processed",
                        trimLeft, trimRight, trimTailLeft, trimTailRight, nmax)

# # for merged or single end reads, input fastq must be .gz compressed:
# cmd <- PrinSeqProcessSE(metaRef=metadataAdapRM, fastq1=metadataAdapRM$AdapRMQualFiltFastq,
#                         outPutSuffix="3processedMerged", trimLeft, trimRight, trimTailLeft, 
#                         trimTailRight, nmax)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done: 
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

If reads are merged and are a single input in step above, no need for next chunk.
Gzip the fastq reads that were INPUT to the PrinSeq processing in step 2-1. 
```{r}

# cmd <- with(metadataAdapRM, paste("gzip ", pathFastq, metadataAdapRM$AdapRMQualFiltFastq, sep=""))
# sapply(cmd, function(x) system(x))
```

For unmerged forward and reverse reads:
```{r}
# Delete singletons:
singletons <- list.files(path = pathFastq, pattern = ".*_singletons.fastq$")
for(k in 1:length(singletons)) {
  cmd <- paste("rm ", pathFastq, singletons[k], sep = "")
  system(cmd)
}

# Rename files as desired:
read1Fastq <- list.files(path = pathFastq, pattern = ".*_1.fastq$", full.names=TRUE)
read2Fastq <- list.files(path = pathFastq, pattern = ".*_2.fastq$", full.names=TRUE)
sapply(read1Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_1.fastq", replacement = ".R1.fastq", pathFastq))
      })
sapply(read2Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_2.fastq", replacement = ".R2.fastq", pathFastq))
      })
processed3Fastq <- list.files(path = pathFastq, pattern = ".*3processed")

# Add fastq names to metadata table:
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed3.R1.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".3processed.R1.fastq", sep = "")
  metadataAdapRem$processed3.R2.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".3processed.R2.fastq", sep = "")
}

# Delete the older fastq files '2processed', only require newest processed. 
processed2Fastq

for(k in 1:length(processed2Fastq)) {
  cmd <- paste("rm ", pathFastq, processed2Fastq[k], sep = "")
  system(cmd)
}
rm(processed2Fastq)
```

For merged or Single-End Reads:
Add name of Poly-A/T, left and right trimmed merged reads .fastq files to the metadataAdapRM tabel:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMTrimLRPolyAT <- paste(metadataAdapRM$LibraryName,
#                                              ".3processedMerged.fastq", sep = "") 
# }
```

2-2. Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix2 <- "G2_PrinSeqGraphTrimLRPolyAT"

# For reads not compressed:
cmd <- MakePrinSeqGraphFiles(metadataAdapRem, metadataAdapRem$processed3.R1.Fastq,
                             prefix, "3processed", metadataAdapRem$processed3.R2.Fastq)

# For merged or single-end reads that are .gz compressed:
# cmd <- MakePrinSeqGraphFiles2(metadataAdapRM, metadataAdapRM$AdapRMTrimLRPolyAT,
#                              prefix, "3processedMerged")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

For unmerged paired-end reads: Add name of graph files to metadata table:
```{r}
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed3GD <- paste(metadataAdapRem$LibraryName,
                                        ".3processed.gd", sep = "") 
}
```

For merged or single-end reads: Add name of graph files to metadata table:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMTrimLRPolyATGraph <- paste(metadataAdapRM$LibraryName,
#                                                   ".3processedMerged.gd", sep = "") 
# }
```

2-3. PrinSeq graph reports of second-stage html file generation:
```{r}
prefix3 <- "G3_PrinSeq_html"

# For paired-end not merged:
cmd <- MakePrinSeqHTML(metadataAdapRem, prefix, metadataAdapRem$processed3GD)

# # For merged or single-end reads:
# cmd <- MakePrinSeqHTML(metadataAdapRM, prefix, metadataAdapRM$AdapRMTrimLRPolyATGraph)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

3-1. Third stage of quality pre-processing with PrinSeq: Poly-A/T tail removal, round 2:
Repeat poly tails trimming, this is because after trimming ends with AAAAAATTTTT that have been 
trimmed for the poly-T will still have the poly-A string.
```{r}
prefix <- "H_PrinSeq2ndPolyAT"

cmd <- PrinSeqProcessPE(metaRef=metadataAdapRem, fastq1=metadataAdapRem$processed3.R1.Fastq, 
                        fastq2=metadataAdapRem$processed3.R2.Fastq, outPutSuffix="4processed",
                        trimTailLeft, trimTailRight, nmax)

# # For merged or single end reads, input fastq must be .gz compressed:
# cmd <- PrinSeqProcessSE(metaRef=metadataAdapRM, fastq1=metadataAdapRM$AdapRMTrimLRPolyAT,
#                         outPutSuffix="4processedMerged", trimTailLeft, trimTailRight, nmax)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

For unmerged forward and reverse reads:
```{r}
# Delete singletons:
singletons <- list.files(path = pathFastq, pattern = ".*_singletons.fastq$")
for(k in 1:length(singletons)) {
  cmd <- paste("rm ", pathFastq, singletons[k], sep = "")
  system(cmd)
}

# Rename files as desired:
read1Fastq <- list.files(path = pathFastq, pattern = ".*_1.fastq$", full.names=TRUE)
read2Fastq <- list.files(path = pathFastq, pattern = ".*_2.fastq$", full.names=TRUE)
sapply(read1Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_1.fastq", replacement = ".R1.fastq", pathFastq))
      })
sapply(read2Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_2.fastq", replacement = ".R2.fastq", pathFastq))
      })
processed4Fastq <- list.files(path = pathFastq, pattern = ".*4processed")

# Add fastq names to metadata table:
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed4.R1.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".4processed.R1.fastq", sep = "")
  metadataAdapRem$processed4.R2.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".4processed.R2.fastq", sep = "")
}

# Delete the older fastq files '2processed', only require newest processed. 
processed3Fastq
for(k in 1:length(processed3Fastq)) {
  cmd <- paste("rm ", pathFastq, processed3Fastq[k], sep = "")
  system(cmd)
}
rm(processed3Fastq)
```

For merged reads: To compress merged reads (Paired-End or Single-End reads)
Don't need the chunk below since we compressed the fastq files already. 
```{r}
# cmd <- with(metadataAdapRM, paste("gzip ", pathFastq, metadataAdapRM$AdapRMTrimLRPolyAT, sep=""))
# sapply(cmd, function(x) system(x))
```

Add name of 2nd polyAT trimmed merged reads .fastq files to the metadataAdapRM tabel:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRM2ndPolyAT <- paste(metadataAdapRM$LibraryName,
#                                              ".4processedMerged.fastq", sep = "") 
# }
```

3-2. Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "H2_PrinSeq2ndTrimPolyATgraphs"
# For reads not compressed:
cmd <- MakePrinSeqGraphFiles(metadataAdapRem, metadataAdapRem$processed4.R1.Fastq,
                             prefix, "4processed", metadataAdapRem$processed4.R2.Fastq)

# For merged or single-end reads that are .gz compressed:
# cmd <- MakePrinSeqGraphFiles2(metadataAdapRM, metadataAdapRM$AdapRM2ndPolyAT,
#                               prefix, "4processedMerged")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

For unmerged paired-end reads: Add name of graph files to metadata table:
```{r}
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed4GD <- paste(metadataAdapRem$LibraryName, ".4processed.gd", sep = "") 
}
```

For merged or single-end reads: Add name of graph files to metadata table:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRM2ndPolyATgraph <- paste(metadataAdapRM$LibraryName,
#                                                ".4processedMerged.gd", sep = "") 
# }
```

3-3. PrinSeq graph reports of third-stage html file generation:
```{r}
prefix3 <- "H3_PrinSeq_html"

# For paired-end not merged:
cmd <- MakePrinSeqHTML(metadataAdapRem, prefix, metadataAdapRem$processed4GD)

# # For merged or single-end reads:
# cmd <- MakePrinSeqHTML(metadataAdapRM, prefix, metadataAdapRM$AdapRM2ndPolyATgraph)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

4-1. Fourth and LAST stage of quality pre-processing with PrinSeq:
Filtering of reads by complexity (DUST) and minimum length
```{r}
prefix <- "I_PrinSeqDustMinLen"

cmd <- PrinSeqProcessPE(metaRef=metadataAdapRem, fastq1=metadataAdapRem$processed4.R1.Fastq, 
                        fastq2=metadataAdapRem$processed4.R2.Fastq, outPutSuffix="5processed",
                        minLen, lcMethod, lcThreshold)

# # For merged or single end reads, input fastq must be .gz compressed:
# cmd <- PrinSeqProcessSE(metaRef=metadataAdapRM, fastq1=metadataAdapRM$AdapRM2ndPolyAT,
#                         outPutSuffix="5processedMerged", minLen, lcMethod, lcThreshold)
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

For unmerged forward and reverse reads:
```{r}
# Delete singletons:
singletons <- list.files(path = pathFastq, pattern = ".*_singletons.fastq$")
for(k in 1:length(singletons)) {
  cmd <- paste("rm ", pathFastq, singletons[k], sep = "")
  system(cmd)
}

# Rename files as desired:
read1Fastq <- list.files(path = pathFastq, pattern = ".*_1.fastq$", full.names=TRUE)
read2Fastq <- list.files(path = pathFastq, pattern = ".*_2.fastq$", full.names=TRUE)
sapply(read1Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_1.fastq", replacement = ".R1.fastq", pathFastq))
      })
sapply(read2Fastq, FUN = function(pathFastq){
      file.rename(from = pathFastq, 
                  to   = sub(pattern = "_2.fastq", replacement = ".R2.fastq", pathFastq))
      })
processed5Fastq <- list.files(path = pathFastq, pattern = ".*5processed")

# Add fastq names to metadata table:
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed5.R1.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".5processed.R1.fastq", sep = "")
  metadataAdapRem$processed5.R2.Fastq <- paste(metadataAdapRem$LibraryName,
                                               ".5processed.R2.fastq", sep = "")
}

# Delete the older fastq files '2processed', only require newest processed. 
processed4Fastq
for(k in 1:length(processed4Fastq)) {
  cmd <- paste("rm ", pathFastq, processed4Fastq[k], sep = "")
  system(cmd)
}
rm(processed4Fastq)
```

For merged reads: To compress merged reads (Paired-End or Single-End reads)
Don't need the chunk below since we compressed the fastq files already. 
```{r}
# cmd <- with(metadataAdapRM, paste("gzip ", pathFastq, metadataAdapRM$AdapRMTrimLRPolyAT, sep=""))
# sapply(cmd, function(x) system(x))
```

For merged or single-end reads:
Add name of 2nd polyAT trimmed merged reads .fastq files to the metadataAdapRM tabel:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMDustMinLen <- paste(metadataAdapRM$LibraryName,
#                                              ".5processedMerged.fastq", sep = "") 
# }
```

Don't need the chunk below since we compressed the fastq files already.
```{r}
# cmd <- with(metadataAdapRM, paste("gzip ", pathFastq, metadataAdapRM$AdapRM2ndPolyAT, sep = ""))
# sapply(cmd, function(x) system(x))
``` 

4-2. Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "I2_PrinSeqDustMinLenGraph"

# For reads not compressed:
cmd <- MakePrinSeqGraphFiles(metadataAdapRem, metadataAdapRem$processed5.R1.Fastq,
                             prefix, "5processed", metadataAdapRem$processed5.R2.Fastq)

# # For merged or single-end reads that are .gz compressed:
# cmd <- MakePrinSeqGraphFiles2(metadataAdapRM, metadataAdapRM$AdapRMDustMinLen,
#                               prefix, "5processedMerged")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

For unmerged paired-end reads: Add name of graph files to metadata table:
```{r}
for(k in 1:nrow(metadataAdapRem)){
  metadataAdapRem$processed5GD <- paste(metadataAdapRem$LibraryName, ".5processed.gd", sep = "") 
}
```

For merged or single-end reads: Add name of graph files to metadata table:
```{r}
# for(k in 1:nrow(metadataAdapRM)){
#   metadataAdapRM$AdapRMDustMinLenGraph <- paste(metadataAdapRM$LibraryName,
#                                                   ".5processedMerged.gd", sep = "") 
# }
```

4-3. PrinSeq graph reports of fourth-stage html file generation:
```{r}
prefix3 <- "I3_PrinSeq_html"
# For paired-end not merged:
cmd <- MakePrinSeqHTML(metadataAdapRem, prefix, metadataAdapRem$processed5GD)

# # For merged or single-end reads:
# cmd <- MakePrinSeqHTML(metadataAdapRM, prefix, metadataAdapRM$AdapRMDustMinLenGraph)

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

To complete the Processing Stage, write the metadata table to future record and for when 
continuing on to data analysis:
Note, for the oospore conversion timecourse off the HiSeq in the folder HiSeq_Analyses2, we
saved the final metadata table a couple of times and now have files with the same infor but 
with different names:
"Final_metadataTable_afterProcessing.csv"
"metadataAdapRemOosporeConvHiSeqAnalyses2.tab.tsv"
```{r}
# Specify which metadata table you've been using:
finalMetadata <- metadataAdapRem
finalName <- "OosporeConversion_Final_metadataTable_afterProcessing.csv"
write.table(finalMetadata, file = finalName, 
            append = FALSE, quote = FALSE, 
            sep = ",", row.names = FALSE)
```

TopHat:
Create folders to put Tophat results and runs the jobs.  
```{r}
prefix <- "J_TophatQsub"
node   <- 2

# For paired-end not merged:
for(j in 1:length(metadataAdapRem$LibraryName)) {
  dir.create(paste(sharedPathAn, metadataAdapRem$LibraryName[j], sep = ""),
             showWarnings = TRUE, recursive = FALSE)
}

cmd <- with(metadataAdapRem, 
            paste(tophat2Path, 
                  " -G ", pyuugff3Path,
                  " -p ", node, 
                  " -o ", sharedPathAn, LibraryName, "/",LibraryName,".TopHat.",
                          format(Sys.time(), "%Y-%m-%d"),
                  " ",    referencesPath, bowind,
                  " ",    pathFastq, processed5.R1.Fastq, " ", pathFastq, processed5.R2.Fastq,
                  sep = ""))

# # For merged or single-end reads:
# for(j in 1:length(metadataAdapRM$LibraryName)) {
#   dir.create(paste(sharedPathAn, metadataAdapRM$LibraryName[j], sep = ""),
#              showWarnings = TRUE, recursive = FALSE)
# }
# cmd <- with(metadataAdapRM, 
#             paste(tophat2Path, 
#                   " -G ", pyuugff3Path,
#                   " -p ", node, 
#                   " -o ", sharedPathAn, LibraryName, "/",LibraryName,".TopHat.",
#                           format(Sys.time(), "%Y-%m-%d"),
#                   " ",    referencesPath, bowind,
#                   " ",    pathFastq, AdapRMDustMinLen, ".gz",
#                   sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```
MUST DO CLEAN UP OF TMP FILES WITHIN FOLDERS
- fix the matching to temp tophat files to be removed
```{r}
# For paired-end not merged
cmd <- with(metadataAdapRem, paste("rm -r ", sharedPathAn, metadataAdapRem$LibraryName, "/", 
                                   metadataAdapRem$LibraryName, ".TopHat.2016-07-19/tmp", sep = ""))

# # For merged or single-end reads:
# cmd <- with(metadataAdapRM, paste("rm -r ", sharedPathAn, metadataAdapRM$LibraryName, "/", 
#                                   metadataAdapRM$LibraryName, ".TopHat.2016-07-10/tmp", sep = ""))
system(cmd)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Setting up the folder date
```{r}
# could have automatic search for most recent
topHatDate <- ".2016-07-19"
```

To run Samtools on the Tophat folder that has the right date
```{r}
prefix <- "K_SamtoolsSortQsub"
# cmd <- with(metadataAdapRM, # For merged or single-end reads
cmd <- with(metadataAdapRem,  # For paired-end not merged
            (paste(samtools1Path, " sort",   " -n ", 
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", "accepted_hits.bam ", sep = ""),
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", LibraryName, "_sn", sep = ""),
                   "\n",
                   samtools1Path, " view ", " -o ",
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", LibraryName, "_sn.sam ", sep = ""),
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", LibraryName, "_sn.bam", sep = ""),
                   "\n",
                   samtools1Path, " sort ",
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", "accepted_hits.bam ", sep = ""),
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat", 
                         topHatDate, "/", LibraryName, "_s", sep = ""),
                   "\n",
                   samtools1Path, " index ", 
                   paste(sharedPathAn, LibraryName, "/", LibraryName, ".TopHat",
                         topHatDate, "/", LibraryName, "_s.bam", sep = ""),
                   sep = "")))
node   <- 1
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```

To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

